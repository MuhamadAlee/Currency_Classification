{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5765,
     "status": "ok",
     "timestamp": 1594983306312,
     "user": {
      "displayName": "Muhammad Alee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3Nm_R2e5t8JgizY5cfhjh3RDwW-P2j7Vv3TJ0=s64",
      "userId": "15643782540892852106"
     },
     "user_tz": -300
    },
    "id": "4EU44tGjY4Qd",
    "outputId": "5a8d6564-f4d8-47e0-fe68-f2c2000bbce6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7648,
     "status": "ok",
     "timestamp": 1594983308216,
     "user": {
      "displayName": "Muhammad Alee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3Nm_R2e5t8JgizY5cfhjh3RDwW-P2j7Vv3TJ0=s64",
      "userId": "15643782540892852106"
     },
     "user_tz": -300
    },
    "id": "HwCnPzi9ZHCH",
    "outputId": "6ae1a2ae-0b61-40b6-b57f-8599e20cfa7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15150,
     "status": "ok",
     "timestamp": 1594983315735,
     "user": {
      "displayName": "Muhammad Alee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3Nm_R2e5t8JgizY5cfhjh3RDwW-P2j7Vv3TJ0=s64",
      "userId": "15643782540892852106"
     },
     "user_tz": -300
    },
    "id": "qwfr6yXIZRZz"
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "# Convolution - input image, applying feature detectors => feature map\n",
    "# 3D Array because colored images\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "# Feature Map - Take Max -> Pooled Feature Map, reduced size, reduce complexity\n",
    "# without losing performance, don't lose spatial structure\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding second convolution layer\n",
    "# don't need to include input_shape since we're done it\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15140,
     "status": "ok",
     "timestamp": 1594983315740,
     "user": {
      "displayName": "Muhammad Alee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3Nm_R2e5t8JgizY5cfhjh3RDwW-P2j7Vv3TJ0=s64",
      "userId": "15643782540892852106"
     },
     "user_tz": -300
    },
    "id": "xEeXmCBjZ1ie"
   },
   "outputs": [],
   "source": [
    "classifier.add(Flatten())\n",
    "\n",
    "\n",
    "# Step 4 - Full Connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 7, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15129,
     "status": "ok",
     "timestamp": 1594983315742,
     "user": {
      "displayName": "Muhammad Alee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3Nm_R2e5t8JgizY5cfhjh3RDwW-P2j7Vv3TJ0=s64",
      "userId": "15643782540892852106"
     },
     "user_tz": -300
    },
    "id": "n25_TaMlZ4vK"
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15824,
     "status": "ok",
     "timestamp": 1594983316451,
     "user": {
      "displayName": "Muhammad Alee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3Nm_R2e5t8JgizY5cfhjh3RDwW-P2j7Vv3TJ0=s64",
      "userId": "15643782540892852106"
     },
     "user_tz": -300
    },
    "id": "mV_qZ8TxZ7IP",
    "outputId": "1a8c7ec5-c84e-4486-c832-04e1b72bf72c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49 images belonging to 7 classes.\n",
      "Found 14 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('/content/drive/My Drive/Datasets/Train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('/content/drive/My Drive/Datasets/Test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3507310,
     "status": "ok",
     "timestamp": 1594986807954,
     "user": {
      "displayName": "Muhammad Alee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3Nm_R2e5t8JgizY5cfhjh3RDwW-P2j7Vv3TJ0=s64",
      "userId": "15643782540892852106"
     },
     "user_tz": -300
    },
    "id": "YllmNvriaOc-",
    "outputId": "4e285eab-df48-4a60-eb7f-08673c77f782"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=250, epochs=10, validation_steps=2000)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 375s 2s/step - loss: 0.0781 - accuracy: 0.9728 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 340s 1s/step - loss: 9.7162e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 352s 1s/step - loss: 2.8198e-04 - accuracy: 1.0000 - val_loss: 5.2400e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 345s 1s/step - loss: 1.2959e-04 - accuracy: 1.0000 - val_loss: 4.4352e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 346s 1s/step - loss: 7.0968e-05 - accuracy: 1.0000 - val_loss: 5.0630e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 347s 1s/step - loss: 4.4611e-05 - accuracy: 1.0000 - val_loss: 2.3428e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 349s 1s/step - loss: 3.2926e-05 - accuracy: 1.0000 - val_loss: 1.0065e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 354s 1s/step - loss: 2.4632e-05 - accuracy: 1.0000 - val_loss: 1.5453e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 341s 1s/step - loss: 1.7906e-05 - accuracy: 1.0000 - val_loss: 8.9978e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 341s 1s/step - loss: 1.3519e-05 - accuracy: 1.0000 - val_loss: 9.7143e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f20a0068908>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                        samples_per_epoch=8000,\n",
    "                        nb_epoch=10,\n",
    "                        validation_data=test_set,\n",
    "                        nb_val_samples=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1594,
     "status": "ok",
     "timestamp": 1594986836161,
     "user": {
      "displayName": "Muhammad Alee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3Nm_R2e5t8JgizY5cfhjh3RDwW-P2j7Vv3TJ0=s64",
      "userId": "15643782540892852106"
     },
     "user_tz": -300
    },
    "id": "hiMl44PLaS8W"
   },
   "outputs": [],
   "source": [
    "classifier.save('/content/drive/My Drive/Datasets/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1594986921287,
     "user": {
      "displayName": "Muhammad Alee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3Nm_R2e5t8JgizY5cfhjh3RDwW-P2j7Vv3TJ0=s64",
      "userId": "15643782540892852106"
     },
     "user_tz": -300
    },
    "id": "7DX9C1RxnWrZ",
    "outputId": "194667c6-4715-445e-98a7-e17a710af701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('/content/drive/My Drive/Datasets/Test/ten/10b.jpg', target_size=(64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "\n",
    "pred=np.argmax(result[0])\n",
    "\n",
    "if pred==0:\n",
    "    print(\"Five Hundred\")\n",
    "elif pred==1:\n",
    "    print(\"Five Thousands\")\n",
    "elif pred==2:\n",
    "    print(\"Thousand\")\n",
    "elif pred==3:\n",
    "    print(\"Fifty\")\n",
    "elif pred==4:\n",
    "    print(\"Hundred\")\n",
    "elif pred==5:\n",
    "    print(\"Ten\")\n",
    "elif pred==6:\n",
    "    print(\"Twenty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "classifier=load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thousand\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('Datasets/Single_Prediction/1000.jpg', target_size=(64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "#training_set.class_indices\n",
    "\n",
    "pred=np.argmax(result[0])\n",
    "\n",
    "if pred==0:\n",
    "    print(\"Five Hundred\")\n",
    "elif pred==1:\n",
    "    print(\"Five Thousands\")\n",
    "elif pred==2:\n",
    "    print(\"Thousand\")\n",
    "elif pred==3:\n",
    "    print(\"Fifty\")\n",
    "elif pred==4:\n",
    "    print(\"Hundred\")\n",
    "elif pred==5:\n",
    "    print(\"Ten\")\n",
    "elif pred==6:\n",
    "    print(\"Twenty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPNOfcxhTENe8Qv9rMlNwJa",
   "collapsed_sections": [],
   "mount_file_id": "1vVXd_yFjleqkNQvxWu0GpRdWcT_g0gvJ",
   "name": "Currency.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
